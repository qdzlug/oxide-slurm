# Slurm Cluster Deployment Project

This project demonstrates a complete end-to-end solution for deploying a Slurm cluster in a cloud environment. It uses **Terraform** to provision the necessary infrastructure on Oxide Cloud (including VPC, instances, disks, firewall rules, and an Ansible inventory file) and **Ansible** to configure the cluster (installing packages, setting up NFS, Munge, and Slurm, and verifying node readiness).

## Project Overview

- **Terraform Module**:  
  - Provisions cloud infrastructure (VPC, subnets, compute instances, disks).
  - Creates firewall rules (for internal cluster traffic and SSH).
  - Generates an Ansible inventory file (`hosts.ini`) based on instance IP addresses.
  - See the [Terraform README](./terraform/README.md) for details.

- **Ansible Module**:  
  - Installs required packages and configures users/groups.
  - Sets up an NFS share on the head (controller) node and mounts it on compute nodes.
  - Manages Munge key generation and distribution.
  - Downloads, builds, and installs Slurm on the head node and distributes its configuration to compute nodes.
  - Performs verification tasks to ensure the cluster is operational.
  - See the [Ansible README](./ansible/README.md) for details.

## Architecture

1. **Infrastructure Provisioning (Terraform):**  
   Terraform provisions a VPC, deploys compute instances (with the first instance designated as the head node and the remaining as compute nodes), creates disks, and configures firewall rules. It also generates an Ansible inventory file for further configuration.

2. **Cluster Configuration (Ansible):**  
   Ansible configures the operating system on each node, sets up NFS for shared package distribution, installs and configures Munge for authentication, builds and installs Slurm, and verifies cluster health.

## How to Use

### 1. Provision Infrastructure with Terraform
- Navigate to the Terraform directory:
  ```bash
  cd terraform
  ```
- Initialize and apply the configuration:
  ```bash
  terraform init
  terraform apply -auto-approve
  ```
- This will create your VPC, instances, firewall rules, and generate the `hosts.ini` file in the project root.

### 2. Configure the Cluster with Ansible
- Navigate to the Ansible directory (or run from the project root if configured accordingly):
  ```bash
  cd ansible
  ```
- Run the Ansible playbook using the generated inventory file:
  ```bash
  ansible-playbook -i ../hosts.ini playbook.yml
  ```

## Troubleshooting

- **Missing Template Files:**  
  If you encounter errors such as "Could not find or access 'slurm.conf.j2'", ensure that the template file exists in the expected location (`roles/slurm/templates/slurm.conf.j2`). Verify your directory structure and file paths.

- **Inventory Issues:**  
  Ensure that the generated `hosts.ini` file correctly groups head and compute nodes. The head node is used to configure and distribute the central `slurm.conf` file.

- **Service Failures:**  
  If Slurm services (such as `slurmdbd`, `slurmctld`, or `slurmd`) are not running, review the verification output and check logs on the affected nodes.

- **Detailed Debugging:**  
  Run Ansible with increased verbosity (e.g. `ansible-playbook -i ../hosts.ini playbook.yml -vvv`) to gather more details about any failures.

## Directory Structure

```
project-root/
├── terraform/
│   ├── main.tf
│   ├── variables.tf
│   ├── outputs.tf
│   ├── terraform.tfvars
│   └── README.md         # Terraform README (detailed instructions)
├── ansible/
│   ├── playbook.yml
│   ├── inventory/hosts.ini   # Generated by Terraform
│   └── roles/
│       ├── common/
│       ├── nfs/
│       ├── munge/
│       ├── slurm/
│       └── verification/
│   └── README.md         # Ansible README (detailed instructions)
└── README.md             # This high-level README
```

## License

This project is released under the [MIT License](LICENSE).

## Contact

For questions or feedback, please contact [Your Name or Email].